II. Background and Observations on Sentiment Expression in SE Texts
In this section, we first introduce SentiStrength [11] which is the basis of SESSION. We then discuss the differences between SE texts and social texts when they express sentiments.
A. How SentiStrength Works 
SentiStrength is a dictionary-based sentiment classifier which is developed for common texts. It contains a series of sentiment dictionaries, including the sentimental words list, the booster word list, and the negative word list. These lists play a vital role in the computation of sentiments. The sentimental words list gives sentiment scores to the matched words. The booster word list contains words that can strengthen or weaken affected sentiment scores. The words in the negative word list are used to flip the sentimental polarity of a word right after it. For the input text, SentiStrength will assign sentiment scores to each word according to the dictionaries and use minor rules to adjust the result. We use samples in Table I to show how SentiStrength works based on its dictionaries and rules. Variables ρ and η respectively refer to the positive and negative scores for each sentence, where +1 ≤ ρ ≤ +5 and −5 ≤ η ≤ −1. To better detect sentiment, the default result of SentiStrength contains both two scores. Only the score of (1, -1) indicates neutrality for a text. However, it also provides a “trinary” option to output an overall sentiment that is either positive, neutral, or negative. It is worth mentioning that SentiStrength determines the sentiment scores based on the sentimental words assigned by the highest positive and negative sentiments without considering the number of clauses in the input text. This setting helps SentiStrength to focus on the most sentimental part of the input text, especially when the text size is large. We follow the same setting in our approach, but use the clauses segmented from the input text as the basis of our proposed filter-adjust rules.
B. Different Expressions between SE Texts and Social Texts
Making close observations on SE texts and social texts, we find visible differences between two types of texts in expressing sentiments. The samples for social texts we selected are 1041 MySpace comments from the SentiStrength benchmark [11]. The samples for SE texts we selected are 4423 Stack Overflow posts from the Senti4SD benchmark [13]. Next, we will introduce our observed differences in detail.
We first find that SE texts tend to express fewer sentiments by comparing the percentage of sentimental texts from two sets of samples. For the 1041 MySpace comments, there are 938 texts manually labeled as sentimental (positive or negative). The percentage of sentimental texts is 90.1%. For the 4423 Stack Overflow posts, there are 2729 texts manually labeled as sentimental. The percentage of sentimental texts is 61.7%. In addition to the fewer sentiments, when it comes to expressing emotions, SE texts are more indirect and dispersed. We use sentimental density to reflect this characteristic of SE texts. The sentimental density ρ of a text equals the number of sentimental words (according to the sentimental words list of SentiStrength) in the text  n_s  divided by the total number of words in the text n_w. The average ρ of the 938 MySpace sentimental texts is 0.148, while the average ρ of 2729 Stack Overflow sentimental texts is 0.092. To more intuitively depict the differences, we show two samples with their ρ values close to the average from the two sets of texts, respectively. The text representing MySpace is “Thanks for the add Jeremy!! Gotta love those Macross toy pics. Sadly I don't have them anymore... ”, while the one representing Stack Overflow is “The error occurs because of looking in the wrong environment (i.e., not inside the data frame). You could explicitly specify the but that would be ugly, awful code. Much better to use as Iselzer suggests.” It can be observed that social texts directly express sentiments, while SE texts usually have to describe the issues first and then express the author’s sentiments about the issues. An additional observation is that “error”, a typical negative word for social texts, is neutral in the SE text to discuss a code issue. 
We then observed that the structure of SE texts is more complicated due to the use of long and complicated sentences in SE texts to describe development-related issues. We thus measure the average length of texts in the two sets of texts by counting the number of characters. The average length of MySpace comments is 102, while the average length of Stack Overflow posts is 169. To show this difference, we also choose two texts with their length close to the average length from each of the two datasets. The text representing MySpace is “HAPPY BIRTHDAY BEAUTIFIL... HOPE YOU SEE MANY MORE.. BETTER YET I KNOW YOU WILL...GOD BLESS YOU..STAY UP”. The whole text basically uses imperative sentences to express blessing. While the text representing Stack Overflow is “I generally do it before importing anything. If you're worried that your module names might conflict with the Python stdlib names, then change your module names!”. The structure of this text, which contains a subjunctive clause, is more complicated.
Thus, we argue that these observed differences lead to the unreliable results provided by off-the-shelf sentiment analysis tools built on social texts, and greatly raise the difficulty to customize these tools for SE texts. The dispersed expression of sentiments requires SE-specified tools to identify whether the author is expressing sentiments in different parts of an SE text. Hence, the complicated sentence structures in SE texts become very important for us to set up filter rules to ignore possible neutral clauses, and adjust rules to enhance the output result. Our approach is built on  SentiStrength with our proposed rules. The evaluation shows that our filter-adjust rules are able to customize SentiStrength for SE texts, even without updating its sentiment dictionary. For example, our approach will ignore the sentence containing the word “error” in the discussed SE-text sample instead of modifying it as “neutral” in the dictionary.

III. Proposed Approach
We propose a three-step approach. First, we preprocess the input SE text and use Stanford CoreNLP[37] for segmentation (Step 1). Second, we use filter rules to identify whether a sentence can trigger the follow-on analysis (Step 2). Third, we use adjust rules to enhance the original output of SentiStrength  (Step 3). It is worth-while noticing that our approach makes no change to SentiStrength’s dictionaries. Each step will be explained with more details in the following subsections.
A. Step 1: Preprocessing and Segmenting SE Texts
First, we adapted the preprocessing methods used by the customized tool SentiStrength-SE [12] to filter out technical words based on regular expressions and filter names containing characters such as “Dear”, “Hi”, “@”. One difference is that we don't filter out the words fully composed by capital letters. These words are likely to express an exaggerated sentiment, rather than be just part of technical texts. We also keep exclamation marks as part of the input for Step 3. The text “FEAR!!!!!!!!!!! ” is a good sample to illustrate the above two differences. Besides, we will also filter out the words surrounded by the following brackets “[]”, “{}”, “<%%>”, and double quotation marks because we think that these words are more likely to be quotations, examples, or technical words and to not express sentiments. For example, in the sentence “CREATE TABLE [[With Spiteful]]]…”, “spiteful” is a negative word but it is part of the table’s name and doesn't express sentiments. Similarly, the negative word “tommyrot” in the sentence “It is actually spelled "tommyrot".” does not indicate negative sentiment because it is quoted as an example. Additionally, the sentence with underline symbols, e.g., “CODE_FRAGMENT”, will be filtered too because this symbol is also a feature of technical text.
Second, to deal with SE texts which have more complicated sentence structures, we introduce Stanford NLP to segment, instead of following SentiStrength to segment texts according to punctuation marks only. Our segmentation first divides the whole text (named as paragraph) into multiple sentences. It then divides each sentence into clauses based on punctuations and conjunctions such as“because”, “but”, and “so”. Furthermore, we use Stanford POS tagger to annotate each word in the clauses of each sentence with its part of speech(POS) tagging. The preprocessed, segmented, and tagged SE texts lays the foundation of the following steps of our approach.
B. Step 2: Matching Patterns to Trigger Follow-on Analysis
To distinguish whether the author is expressing sentiments or describing issues, we propose our filter rules. Specifically, any sentence that did not fit the following three patterns will be filtered out. Only the sentence that matches at least one defined pattern will be considered as likely to express sentiments, and will go to the next step for calculating its sentiment scores. A detailed description of patterns is as follows. 
1) Direct Sentiment Pattern. A given sentence fits Direct Sentiment Pattern when it matches just one of the following six situations: (1) it contains the exclamation marks; (2) it contains emoji recorded in the SentiStrength’s emoji list, such as “ :) ”; (3) it contains interjection word according to the tagged POS, such as “wow”; (4) it contains the four four-letter curse words that respectively start with letters “fu”, “da”, “sh”, and “he”; (5) at least one of its given clauses starts with a sentimental word (except “please” and “plz”); (6) it is an imperative sentence and has a sentimental density larger than 0.3. 
Intuitively, the first four situations indicate that the authors strongly expressed their sentiments. Meanwhile, we propose the fifth and the sixth situations to deal with imperative sentences. The fifth situation is proposed to cover the following two sample sentences: “Thanks for your patience.”  and “Owen, thanks for the slides.”. We exclude“please” and “plz” in the fifth situation because they are more likely to express requests instead of their intended positive sentiments. The sixth situation is proposed to cover the following sample sentence: “Sounds good.” . How to calculate the sentimental density for each sentence is discussed in Section II.B.
2) Decorated Sentiment Pattern. A given sentence fits Decorated Sentiment Pattern when it contains a sentimental word that is an adverb, or it contains a sentimental word that is decorated by an adverb (implying that this sentimental word must be a verb or an adjective). We suggest that when using sentimental adverbs, or adverbs to decorate a sentimental word, the author is determined to express her sentiments in the text because adverbs are used to indicate degree or scope. For example, in the sentence “This is very frustrating.”, the adverb “very” indicates a deeper frustration (i.e., negative sentiment). While in the sentence “The performance degrades horrendously”, the adverb “horrendously” indicates the degree of performance degradation is too large and thus showing the author’s negative sentiment as well. Furthermore, for the three adverbs “always”, “even”, and “still”, we will find decorated sentimental words from these words to the end of the sentence because they have a wider coverage based on their semantics. Finally, we treat “how”, “sort of”, and “enough” (after sentimental words) as adverbs because they are also highly likely to indicate the degree or scope of potential sentiments.
3) “About Me” Pattern: A given sentence fits “About Me” Pattern when it matches the following three situations: (1) its subject is “I” and it contains a sentimental word (e.g. “I like…”); (2) it contains a sentimental verb followed by the object “me”  (e.g. “…confuse me”); (3) it contains a sentimental adjective or noun that follows “me” (e.g. “…make me confused”); (4) it contains a sentimental word that is decorated by “my” (e.g., “This was my bad.”). We propose the four situations because we suggest that the author is determined to express her sentiments in the first-person view. On contrary, the third-person view is usually more likely to describe a fact, instead of expressing sentiments. For example, the sentence  “he hates p tags, clearly” is manually labeled as neutral.
4) “Judgement” Pattern: A given sentence fits “Judgement” Pattern when it contains the following four sentence structures (1) “be verb + sentimental adjectives/nouns” (e.g., “It's ugly and inefficient”); (2) “pronoun + sentimental verb” (e.g., “This sucks so much.”); (3) “get + sentimental word” (e.g., “The problem just gets worse.”); (4) “sentimental nouns + be verb” (e.g., “The biggest reason for failure is your carelessness”); (4) “a/an/the + adjective + noun” (“It has an excellent command line interface.”). We argue that the author usually expresses her sentiments when she makes a judgement to other things or people, and the five proposed situations can largely cover the potential judge-and-express scenarios.
C. Step 3: Adjusting the Sentiment Analysis
We argue that sentence structures are also helpful to better understand expressed sentiments in SE texts. So we propose to adjust rules based on SentiStrength to further enhance the results.
1) Recognizing Subjunctive Mood: Subjunctive mood expresses the author's subjective wishes, suspicions, suggestions, or hypotheses, but does not express real sentiments. Therefore, we ignore the sentimental words occurred in clauses of subjunctive mood. Our approach identifies subjunctive mood by recognizing “if” and “unless” as conditional adverbials in the clauses of a given sentence. We will not identify the sentiments in these clauses. For example, in the sentence “If you're really worried about this, Java is not the language for you.” the negative sentimental word “worried” is in the subjunctive clause, so it reflects no facts and does not express the author’s sentiments. 
2) Identifying Polysemous Words by the Sentence Structure: SentiStrength assigns a sentimental score to each sentimental word. However, when sentimental words express different meanings according to the different sentence structures, a single sentimental score will lead to possibly wrong results. During our observations, we summarized several polysemous words that can easily lead to mistakes. These words are categorized into two groups. We then confirm the meaning of first-group words based on the POS tags, and the meaning of second-group words based on their collocations with other words.
The first group of polysemous words that can be confirmed by the POS tags is as follows:
 Like: SentiStrength detects this word as positive. In the sentence “I like playing with you”, the word “like” is positive and it means that the subject prefers to do something. However, in the sentence “ it looks like this. ”, its meaning is close to “similar to” and it doesn’t express positive sentiments. When “like” means “ similar to”, its POS is a preposition. So when its POS is preposition, we do not mark this word as positive, but as neutral instead. 
Pretty and Super: SentiStrength detects these words as positive. In the sentence “She is pretty. ”, the word “pretty” is positive and it means someone is attractive. However, in the sentence “ I'm pretty sure ” its meaning is close to “very” and it doesn’t express positive sentiments. When “pretty” means “very”, its POS is an adverb. So when its POS is an adverb, we do not mark this word as positive but as neutral. It will also play the role of booster words that can strengthen the intensity of the following sentiment word, like “very”. “Super” is similar to “pretty”. When its POS is an adverb and it is used to indicate something with a high or extreme degree, we detect it as neutral and it will play the role of booster words as well.
Block and Force: SentiStrength detects these words as negative. In sentences “ Lack of training acts as a block to progress in a career.”, the word “block” is negative and it means something that makes movement or progress difficult or impossible, but in sentences similar to “ I'm sure at first the code blocks”, it means a quantity of something that is considered as a single unit and does not express any negative sentiments. When “block” means “ a unit”, its POS is a noun. So when its POS is noun, we do not mark it as negative but as neutral. “Force” is similar to “block”. When its POS is a noun, it means physical strength and we mark it as neutral instead of negative.
The second group of polysemous words that can be confirmed by their collocations with other words is as follows:
Lying: SentiStrength detects the word as negative. In the sentence “He was lying.”, the word “lying” is negative and it means something deviating from the truth, but in sentences similar to “It's lying all over the internet.”, its meaning is close to “be in” and it does not express negative sentiments. When “lying” means “be in”, it is often used with prepositions, except “to” (excluding the phrase “lie to”). So when we recognize this collocation, we do not mark it as negative but as neutral.
Spite and Kind: SentiStrength detects the word “spite” as negative, but in the phrase “in spite of", the whole phrase represents a turning relationship and expresses no negative sentiments. So when found in this phrase, we do not mark it as negative but as neutral. “Kind” is similar to “spite”. In the phrase “kind of", the meaning of the phrase is close to “ to some extent” and the phrase expresses no positive sentiments. So we do not detect it as positive but as neutral when found in this phrase.
Miss: The word “miss” is assigned both a positive score 02 and a negative score 02 by SentiStrength because when its meaning is close to “remember fondly”, it is frequently used to express sadness and loves simultaneously. However, when its meaning is close to “notice something not there”, it expresses negative sentiments in SE texts. According to our observation, when it means “remember fondly”, it is often followed by personal pronouns. When it means “notice something not there”, it is followed by the object. Therefore, we will check the object of this word, only when its object is a personal pronoun, we will calculate its positive and negative sentiments at the same time.
3) Dealing with Negations. The original rule about negations in SentiStrength will flip the polarity of a sentimental word by multiplying a factor of -0.5 when a negation word is right in front of it. This rule overcompensates and ignores too many negation scenarios, especially for SE texts. For example, the sentiment of this text “not to worry, it was a permissions issue with the file.” will be identified as positive according to the original negation rule, but it is labeled as neutral. Instead in our approach, the words in the negation words list and the words ending with “’t” (e.g., “isn’t”) will neutralize the sentiment of the words within the following three words (“to” excluded). We also add three more words “nothing”, “no”, and “without” (not in the original negation list of SentiStrength) to neutralize the sentiment of the first word (“to” excluded) right behind them. The limited negation scope of the added three negation words is because their POS are nouns or prepositions, while the negation words in the original list or ending with “’t” are auxiliary verbs.
D. Summary through a Sample SE Text
We now use the following sample SE text to show how SESSION works: “ This app is a really good in spite of some (minor) shortcomings. Its font sizes will get bigger or smaller to fit in the space allocated for them which I don't like. If you can solve the problem, I believe it will be more practical. Overall, it's a good app though.”. The sentiment of this text is manually labeled as positive. The analysis and results from original SentiStrength are shown in Table II, while the analysis and results from SESSION is shown in Table III. It can be observed that, based on our proposed filter rules and adjust rules (Step 2 and Step 3) that rely on the segmentation and POS tagging of preprocessed SE texts in Step 1, SESSION correctly identifies the positive sentiment for this text, while SentiStrength is misled by the text to wrongly identify its sentiment as negative.